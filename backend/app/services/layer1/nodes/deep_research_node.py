"""
MINDYARD - Deep Research Node
Gemini API ã‚’ä½¿ç”¨ã—ãŸ Deep Research ãƒãƒ¼ãƒ‰

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ‰¿èªå¾Œã«å®Ÿè¡Œã•ã‚Œã€å…ƒã®ã‚¯ã‚¨ãƒªã«åŸºã¥ã„ã¦è©³ç´°ãªãƒªã‚µãƒ¼ãƒã‚’è¡Œã„ã€
çµæœã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿”ã™ã€‚
"""
import os
from typing import Any, Dict, Optional

from app.core.llm import llm_manager
from app.core.llm_provider import LLMProvider, LLMUsageRole
from app.core.logger import get_traced_logger
from app.core.config import settings

logger = get_traced_logger("DeepResearchNode")

_SYSTEM_PROMPT = """ã‚ãªãŸã¯MINDYARDã® Deep Research ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ã€å¾¹åº•çš„ã‹ã¤åŒ…æ‹¬çš„ãªèª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

### èª¿æŸ»æ–¹é‡:
1. **å¤šè§’çš„ãªè¦–ç‚¹**: è¤‡æ•°ã®è¦³ç‚¹ã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚’åˆ†æã™ã‚‹
2. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: è¦‹å‡ºã—ãƒ»ç®‡æ¡æ›¸ãã‚’ä½¿ã£ã¦æƒ…å ±ã‚’æ•´ç†ã™ã‚‹
3. **ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹**: ä¸»å¼µã«ã¯æ ¹æ‹ ã‚„å‡ºå…¸ã®æ–¹å‘æ€§ã‚’ç¤ºã™
4. **å®Ÿç”¨æ€§é‡è¦–**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–ã‚Œã‚‹ã‚ˆã†ãªå…·ä½“çš„ãªæƒ…å ±ã‚’æä¾›ã™ã‚‹

### å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
- æ¦‚è¦ï¼ˆ1-2æ–‡ã®ã‚µãƒãƒªãƒ¼ï¼‰
- ä¸»è¦ãªç™ºè¦‹ãƒ»çŸ¥è¦‹ï¼ˆç®‡æ¡æ›¸ãï¼‰
- è©³ç´°åˆ†æï¼ˆå„ãƒã‚¤ãƒ³ãƒˆã®æ˜ã‚Šä¸‹ã’ï¼‰
- æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ææ¡ˆ

### æ³¨æ„äº‹é …:
- æ—¥æœ¬èªã§å¿œç­”ã™ã‚‹
- ç¢ºè¨¼ã®ãªã„æƒ…å ±ã¯ã€Œã€œã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€ç­‰ã¨æ˜è¨˜ã™ã‚‹
- å°‚é–€ç”¨èªã«ã¯ç°¡æ½”ãªèª¬æ˜ã‚’ä»˜ã‘ã‚‹
"""

# Gemini Deep Research ç”¨ã®ãƒ¢ãƒ‡ãƒ«è¨­å®š
# ç’°å¢ƒå¤‰æ•° GEMINI_DEEP_RESEARCH_MODEL ã§ä¸Šæ›¸ãå¯èƒ½
_DEFAULT_RESEARCH_MODEL = "gemini-2.0-flash-thinking-exp"


def _get_research_provider() -> Optional[LLMProvider]:
    """Deep Research ç”¨ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’å–å¾—ï¼ˆDEEP ãƒ†ã‚£ã‚¢ã‚’ä½¿ç”¨ï¼‰"""
    try:
        return llm_manager.get_client(LLMUsageRole.DEEP)
    except Exception:
        return None


async def run_deep_research_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Deep Research ãƒãƒ¼ãƒ‰: Gemini API ã‚’ä½¿ç”¨ã—ãŸè©³ç´°ãƒªã‚µãƒ¼ãƒ

    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®ã‚¯ã‚¨ãƒªã«åŸºã¥ã„ã¦è©³ç´°ãªãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œã—ã€
    åŒ…æ‹¬çš„ãªèª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    input_text = state["input_text"]
    previous_response = state.get("previous_response", "")
    provider = _get_research_provider()

    if not provider:
        return {
            "response": (
                "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚Deep Research ã‚µãƒ¼ãƒ“ã‚¹ãŒç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\n"
                "é€šå¸¸ã®å›ç­”ã‚’ã”å‚ç…§ãã ã•ã„ã€‚"
            ),
        }

    try:
        await provider.initialize()

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å‰å›ã®å›ç­”ã‚‚å«ã‚ã‚‹
        research_query = input_text
        if previous_response:
            research_query = (
                f"å…ƒã®è³ªå•: {input_text}\n\n"
                f"åˆå›ã®å›ç­”ï¼ˆã“ã‚Œã‚’æ·±æ˜ã‚Šã—ã¦ãã ã•ã„ï¼‰:\n{previous_response}"
            )

        logger.info(
            "Deep Research request",
            metadata={"query_preview": research_query[:200]},
        )

        result = await provider.generate_text(
            messages=[
                {"role": "system", "content": _SYSTEM_PROMPT},
                {"role": "user", "content": research_query},
            ],
            temperature=0.3,
        )

        research_response = result.content
        logger.info(
            "Deep Research completed",
            metadata={"response_preview": research_response[:200]},
        )

        return {
            "response": f"ğŸ”¬ **Deep Research çµæœ**\n\n{research_response}",
        }

    except Exception as e:
        logger.warning("Deep Research failed", metadata={"error": str(e)})
        return {
            "response": (
                "Deep Research ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n"
                "é€šå¸¸ã®å›ç­”ã‚’ã”å‚ç…§ãã ã•ã„ã€‚å†åº¦ãŠè©¦ã—ã„ãŸã ãã“ã¨ã‚‚ã§ãã¾ã™ã€‚"
            ),
        }
